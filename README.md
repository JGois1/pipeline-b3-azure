# üìä Pipeline de Dados da B3 com Azure
Este projeto √© um estudo pr√°tico sobre a constru√ß√£o de um pipeline de dados na nuvem Azure. O objetivo √© automatizar a extra√ß√£o, transforma√ß√£o e carga (ETL) dos arquivos di√°rios de cota√ß√µes da B3 em um banco de dados SQL para futuras an√°lises.

#### Alunos: Jo√£o Gois de Otoni, Marcus Vinicius Azevedo Moreira

### üöÄ Tecnologias Utilizadas
Azure Blob Storage: Para armazenar os arquivos brutos (.txt) de cota√ß√µes.

Azure SQL Database: Para guardar os dados j√° limpos, tratados e prontos para consulta.

Azure Data Factory: √â o orquestrador do projeto, respons√°vel por automatizar todo o fluxo de dados.

Python: Utilizado em scripts de apoio para testes de conex√£o e upload inicial de arquivos.

### ‚öôÔ∏è Como Configurar o Projeto
Para executar os scripts Python (upload_blob.py e testar_conexao_db.py) localmente, √© necess√°rio criar um arquivo config.ini na raiz do projeto.

Este arquivo deve conter as chaves de acesso e senhas dos servi√ßos da Azure. Por quest√µes de seguran√ßa, ele √© ignorado pelo Git e n√£o deve ser enviado para o reposit√≥rio.

### üìã Status Atual
O projeto est√° em desenvolvimento. A infraestrutura base e o pipeline de c√≥pia de dados foram conclu√≠dos.
